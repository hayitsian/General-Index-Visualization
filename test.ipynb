{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Index Unit Test\n",
    "Small scale testing of general index data & processing\n",
    "\n",
    "---\n",
    "Created 6/3/22 by Ian Hay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import networkx as nx\n",
    "from pyvis.network import Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility\n",
    "\n",
    "def loadTextFileIntoDataframe(filepath, splittingChar=\"\\t\"):\n",
    "    \"\"\"\n",
    "    Opens the given filepath into a pandas dataframe.\n",
    "    Splits the list by the denoted character, by default tab.\n",
    "    \"\"\"\n",
    "    with open(filepath) as file:\n",
    "        data = file.readlines()\n",
    "    df = pd.DataFrame()\n",
    "    for line in data:\n",
    "        lineSplit = line.split(splittingChar)\n",
    "        df = df.append([lineSplit])\n",
    "    return df\n",
    "\n",
    "def numSimilarStrings(stringList1, stringList2):\n",
    "    \"\"\"\n",
    "    Given two lists of strings, returns the number of strings they both share.\n",
    "    In other words, the size of the subset intersection of stringList1 and stringList2.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for string in stringList1:\n",
    "        if string in stringList2:\n",
    "            count = count + 1\n",
    "    return count\n",
    "\n",
    "def getUniqueWordsColumn(df, column, newColumnName, nonWords=[]):\n",
    "    \"\"\"\n",
    "    Given a dataframe and column, constructs a new column with name newColumnName\n",
    "    of the unique words in  df[column]\n",
    "    The object in  df[column]  must be a list of strings\n",
    "    \"\"\"\n",
    "    df[newColumnName] = df[column]\n",
    "    for row in range(len(df[newColumnName])):\n",
    "        df[newColumnName][row] = df[column].iloc[row]\n",
    "        string_list = []\n",
    "        for string in df[newColumnName].iloc[row]:\n",
    "            string_list.append(string.split(\" \"))\n",
    "        string_list = list(itertools.chain(*string_list)) # concatenates nested list into 1D list\n",
    "        string_list = list(set(string_list)) # grabs only unique string items\n",
    "        for nonword in nonWords:\n",
    "            if nonword in string_list:\n",
    "                string_list.remove(nonword)\n",
    "        df[newColumnName].iloc[row] = string_list\n",
    "    return df\n",
    "\n",
    "\n",
    "# performance building adjMatrix on combined test set:\n",
    "# * time for 100 iterations:  430.5321 seconds\n",
    "# *     time per iteration: 4.305321 seconds\n",
    "#\n",
    "# *: timed on 16-thread CPU\n",
    "def buildAdjacencyMatrixByColumn(df, column):\n",
    "    \"\"\"\n",
    "    Given a dataframe and a column, constructs an adjacency matrix\n",
    "    of size [n x n] where  n  is the number of rows of the dataframe.\n",
    "    The adjacency matrix represents the number of alike elements.\n",
    "    The object in  df[column]  must be a list of values.\n",
    "    \"\"\"\n",
    "    n = len(df[column])\n",
    "    adjMatrix = np.zeros((n, n))\n",
    "    for n1 in range(n):\n",
    "        ngram1 = df[column].iloc[n1]\n",
    "        for n2 in range(n):\n",
    "            ngram2 = df[column].iloc[n2]\n",
    "            numSimilar = numSimilarStrings(ngram1, ngram2)\n",
    "            adjMatrix[n1][n2] = numSimilar\n",
    "            if n1 == n2:\n",
    "                adjMatrix[n1][n2] = 0 # removes recursive edges\n",
    "            if numSimilar == 1:\n",
    "                adjMatrix[n1][n2] = 0 # removes edges with 1 similarity to reduce complexity\n",
    "    return adjMatrix\n",
    "\n",
    "\n",
    "def visualizeNetworkHTML(adjMatrix, filename):\n",
    "    \"\"\"\n",
    "    Given an adjacency matrix and the filename to save to, builds an HTML\n",
    "    graph of that network.\n",
    "    Uses pyvis to build an interactive HTML graph of a network from its adjacency matrix.\n",
    "    Uses NetworkX to work with adjacency matrix.\n",
    "    \"\"\"\n",
    "    G = nx.from_numpy_matrix(adjMatrix)\n",
    "    net = Network(width=\"1920px\", height=\"1080px\", notebook=True)\n",
    "    net.barnes_hut()\n",
    "    net.from_nx(G)\n",
    "    net.show(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard coded things\n",
    "columnDict = {0: \"hash\", 1: \"ngram\", 2: \"ngram_lc\", 3: \"ngram_num_tokens\", 4: \"ngram_count\", 5: \"term_freq\", 6: \"doc_count\"}\n",
    "non_words = [\"a\", \"at\", \"an\", \"am\", \"and\", \"that\", \"like\", \"for\", \"by\", \"i\", \"in\", \"of\", \"or\", \"be\", \"use\", \"as\", \"on\", \"the\", \"to\", \"with\", \"-pron-\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>ngram_lc</th>\n",
       "      <th>ngram_num_tokens</th>\n",
       "      <th>ngram_count</th>\n",
       "      <th>term_freq</th>\n",
       "      <th>doc_count</th>\n",
       "      <th>ngram_words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hash</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3002e8a37ec9d00a67bdf0004b8628c35d72068d</th>\n",
       "      <td>[antediluvian, antediluvian humanity]</td>\n",
       "      <td>[antediluvian, antediluvian humanity]</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[0.0000097323600973236, 0.0000097323600973236]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[antediluvian, humanity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005b3bf055ddcb3c25e4742a72ee16728934efd</th>\n",
       "      <td>[antediluvian, antediluvian refrain, follow by...</td>\n",
       "      <td>[antediluvian, antediluvian refrain, follow by...</td>\n",
       "      <td>[1, 2, 4, 5]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>[0.00028050490883590464, 0.0002805049088359046...</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>[antediluvian, refrain, follow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005ebfe5508340797dbfcce8454f3d3f6f76eb1</th>\n",
       "      <td>[antediluvian, antediluvian dream, cave of -PR...</td>\n",
       "      <td>[antediluvian, antediluvian dream, cave of -pr...</td>\n",
       "      <td>[1, 2, 4, 5, 5]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>[0.00009109127345600292, 0.0000910912734560029...</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>[cave, antediluvian, dream, mammoth]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30064ae161de1e9a96992be108c195796f13e72a</th>\n",
       "      <td>[Hennig86 program, routine in the Hennig86, ro...</td>\n",
       "      <td>[hennig86 program, routine in the hennig86, ro...</td>\n",
       "      <td>[2, 4, 5, 1]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>[0.00019790223629527012, 0.0001979022362952701...</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>[program, hennig86, routine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30136ab3788ab8e8be6b939901ec669a41ef896a</th>\n",
       "      <td>[antediluvian]</td>\n",
       "      <td>[antediluvian]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.00005075111652456354]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[antediluvian]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      ngram  \\\n",
       "hash                                                                                          \n",
       "3002e8a37ec9d00a67bdf0004b8628c35d72068d              [antediluvian, antediluvian humanity]   \n",
       "3005b3bf055ddcb3c25e4742a72ee16728934efd  [antediluvian, antediluvian refrain, follow by...   \n",
       "3005ebfe5508340797dbfcce8454f3d3f6f76eb1  [antediluvian, antediluvian dream, cave of -PR...   \n",
       "30064ae161de1e9a96992be108c195796f13e72a  [Hennig86 program, routine in the Hennig86, ro...   \n",
       "30136ab3788ab8e8be6b939901ec669a41ef896a                                     [antediluvian]   \n",
       "\n",
       "                                                                                   ngram_lc  \\\n",
       "hash                                                                                          \n",
       "3002e8a37ec9d00a67bdf0004b8628c35d72068d              [antediluvian, antediluvian humanity]   \n",
       "3005b3bf055ddcb3c25e4742a72ee16728934efd  [antediluvian, antediluvian refrain, follow by...   \n",
       "3005ebfe5508340797dbfcce8454f3d3f6f76eb1  [antediluvian, antediluvian dream, cave of -pr...   \n",
       "30064ae161de1e9a96992be108c195796f13e72a  [hennig86 program, routine in the hennig86, ro...   \n",
       "30136ab3788ab8e8be6b939901ec669a41ef896a                                     [antediluvian]   \n",
       "\n",
       "                                         ngram_num_tokens      ngram_count  \\\n",
       "hash                                                                         \n",
       "3002e8a37ec9d00a67bdf0004b8628c35d72068d           [1, 2]           [1, 1]   \n",
       "3005b3bf055ddcb3c25e4742a72ee16728934efd     [1, 2, 4, 5]     [1, 1, 1, 1]   \n",
       "3005ebfe5508340797dbfcce8454f3d3f6f76eb1  [1, 2, 4, 5, 5]  [1, 1, 1, 1, 1]   \n",
       "30064ae161de1e9a96992be108c195796f13e72a     [2, 4, 5, 1]     [1, 1, 1, 1]   \n",
       "30136ab3788ab8e8be6b939901ec669a41ef896a              [1]              [1]   \n",
       "\n",
       "                                                                                  term_freq  \\\n",
       "hash                                                                                          \n",
       "3002e8a37ec9d00a67bdf0004b8628c35d72068d     [0.0000097323600973236, 0.0000097323600973236]   \n",
       "3005b3bf055ddcb3c25e4742a72ee16728934efd  [0.00028050490883590464, 0.0002805049088359046...   \n",
       "3005ebfe5508340797dbfcce8454f3d3f6f76eb1  [0.00009109127345600292, 0.0000910912734560029...   \n",
       "30064ae161de1e9a96992be108c195796f13e72a  [0.00019790223629527012, 0.0001979022362952701...   \n",
       "30136ab3788ab8e8be6b939901ec669a41ef896a                           [0.00005075111652456354]   \n",
       "\n",
       "                                                doc_count  \\\n",
       "hash                                                        \n",
       "3002e8a37ec9d00a67bdf0004b8628c35d72068d           [1, 1]   \n",
       "3005b3bf055ddcb3c25e4742a72ee16728934efd     [1, 1, 1, 1]   \n",
       "3005ebfe5508340797dbfcce8454f3d3f6f76eb1  [1, 1, 1, 1, 1]   \n",
       "30064ae161de1e9a96992be108c195796f13e72a     [1, 1, 1, 1]   \n",
       "30136ab3788ab8e8be6b939901ec669a41ef896a              [1]   \n",
       "\n",
       "                                                                   ngram_words  \n",
       "hash                                                                            \n",
       "3002e8a37ec9d00a67bdf0004b8628c35d72068d              [antediluvian, humanity]  \n",
       "3005b3bf055ddcb3c25e4742a72ee16728934efd       [antediluvian, refrain, follow]  \n",
       "3005ebfe5508340797dbfcce8454f3d3f6f76eb1  [cave, antediluvian, dream, mammoth]  \n",
       "30064ae161de1e9a96992be108c195796f13e72a          [program, hennig86, routine]  \n",
       "30136ab3788ab8e8be6b939901ec669a41ef896a                        [antediluvian]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data in \"data\" folder derived from: \n",
    "filenameAnte = \"data/doc_ngrams/sample.fgrep.antediluvian.txt\"\n",
    "filepathHennig = \"data/doc_ngrams/sample.fgrep.Hennig86.txt\"\n",
    "\n",
    "df_antedivulian = loadTextFileIntoDataframe(filepath=filenameAnte)\n",
    "df_hennig = loadTextFileIntoDataframe(filepath=filepathHennig)\n",
    "df = pd.concat([df_antedivulian, df_hennig])\n",
    "df.drop(7, axis=1, inplace=True)\n",
    "df.rename(columns=columnDict, inplace=True)\n",
    "df = df.groupby(\"hash\").agg(list)\n",
    "\n",
    "df = getUniqueWordsColumn(df, \"ngram_lc\", \"ngram_words\", nonWords=non_words)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = Timer(\"buildAdjacencyMatrixByColumn(df, \\\"ngram_words\\\")\", \"from __main__ import buildAdjacencyMatrixByColumn, df\")\n",
    "# t.timeit(number=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_try = [\"ngram_lc\", \"ngram_words\"]\n",
    "filename = \"GIgraph_test_\"\n",
    "for col in cols_to_try:\n",
    "    adjmatrix = buildAdjacencyMatrixByColumn(df, col)\n",
    "    visualizeNetworkHTML(adjMatrix=adjmatrix, filename=filename+col+\".html\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74a87f91cde4fc93505a958135b0eb2fe5f761a6a4ac2799970d07df29216479"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
